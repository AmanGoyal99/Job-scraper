name: Job Scraper

on:
  push:
    branches:
      - main
  schedule:
    # Run every 2 hours at :05 minutes past the hour
    - cron: '5 */2 * * *'
  workflow_dispatch: # Allow manual trigger
    inputs:
      scrapers:
        description: 'Which scrapers to run'
        required: false
        default: 'all'
        type: choice
        options:
          - 'all'
          - 'microsoft'
          - 'amazon'
          - 'apple'
          - 'microsoft+amazon'
          - 'microsoft+apple'
          - 'amazon+apple'
      hours_back:
        description: 'Hours to look back for jobs'
        required: false
        default: '2'
        type: string
      pages:
        description: 'Number of pages to fetch'
        required: false
        default: '3'
        type: string

jobs:
  scrape-jobs:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install uv
      uses: astral-sh/setup-uv@v3
      with:
        version: "latest"

    - name: Install dependencies
      run: |
        uv venv
        uv pip install -r requirements.txt

    - name: Run Microsoft job scraper
      if: ${{ github.event.inputs.scrapers == 'microsoft' || github.event.inputs.scrapers == 'all' || github.event.inputs.scrapers == 'microsoft+amazon' || github.event.inputs.scrapers == 'microsoft+apple' || github.event.inputs.scrapers == '' }}
      env:
        WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
      run: |
        # Use manual input values or defaults for scheduled runs
        HOURS_BACK="${{ github.event.inputs.hours_back || '2' }}"
        PAGES="${{ github.event.inputs.pages || '3' }}"

        echo "Running Microsoft scraper with hours_back=${HOURS_BACK}, pages=${PAGES}"

        uv run python scrape.py --webhook \
          --hours ${HOURS_BACK} \
          --pages ${PAGES} \
          --quiet

    - name: Run Amazon job scraper
      if: ${{ github.event.inputs.scrapers == 'amazon' || github.event.inputs.scrapers == 'all' || github.event.inputs.scrapers == 'microsoft+amazon' || github.event.inputs.scrapers == 'amazon+apple' || github.event.inputs.scrapers == '' }}
      env:
        WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
      run: |
        # Use manual input values or defaults for scheduled runs
        HOURS_BACK="${{ github.event.inputs.hours_back || '2' }}"
        PAGES="${{ github.event.inputs.pages || '3' }}"

        echo "Running Amazon scraper with hours_back=${HOURS_BACK}, pages=${PAGES}"

        uv run python amazon.py --webhook \
          --hours ${HOURS_BACK} \
          --pages ${PAGES} \
          --quiet

    - name: Run Apple job scraper
      if: ${{ github.event.inputs.scrapers == 'apple' || github.event.inputs.scrapers == 'all' || github.event.inputs.scrapers == 'microsoft+apple' || github.event.inputs.scrapers == 'amazon+apple' || github.event.inputs.scrapers == '' }}
      env:
        WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
      run: |
        # Use manual input values or defaults for scheduled runs
        HOURS_BACK="${{ github.event.inputs.hours_back || '2' }}"
        PAGES="${{ github.event.inputs.pages || '3' }}"

        echo "Running Apple scraper with hours_back=${HOURS_BACK}, pages=${PAGES}"

        uv run python apple.py --webhook \
          --hours ${HOURS_BACK} \
          --pages ${PAGES} \
          --quiet

    - name: Log completion
      run: |
        SCRAPERS="${{ github.event.inputs.scrapers || 'all' }}"
        echo "Job scrapers completed at $(date)"
        echo "Scrapers run: ${SCRAPERS}"
        echo "Next run scheduled for $(date -d '+2 hours')"